{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from basic_nlp import *\n",
    "from json_io import *\n",
    "import datetime\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "import re\n",
    "from random import shuffle\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to run on each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def keyToStr(d):\n",
    "    new = {}\n",
    "    for key,value in d.items():\n",
    "        new[\" \".join(key)] = value\n",
    "    return new\n",
    "\n",
    "from re import sub\n",
    "\n",
    "TWEET_LINK_RE = \"https://t.co/(\\w)+\"\n",
    "TWEET_HANDLE_RE = \"@(\\w)+\"\n",
    "HASHTAG_RE = \"#(\\w)+\"\n",
    "\n",
    "def feature(tweet):\n",
    "    tweet = sub(TWEET_HANDLE_RE, \"NameTOK\", tweet)\n",
    "    tweet = sub(TWEET_LINK_RE, \"LinkTOK\", tweet)\n",
    "    tweet = sub(HASHTAG_RE, \"\", tweet)\n",
    "    tweet = sub(\"the\", \"\", tweet)\n",
    "    tweet = sub(\"The\", \"\", tweet)\n",
    "    tokens = tokenize(tweet)\n",
    "    ull = upperLowerLen(tokens)\n",
    "    cases = wordCases(ull)\n",
    "    tagged = pos(tokens)\n",
    "    chunked = chunk(tagged)\n",
    "    (tokens, postags) = tokNoNE(chunked)\n",
    "    puncuationFreqDict = punctuationFeatures(tweet)\n",
    "    suffreq = dict(freq(tokenSuffixes(tokens)))\n",
    "    normSuffFreq = {}\n",
    "    norm2SuffFreq = {}\n",
    "    sumSuf = sum(suffreq.values())\n",
    "    for key, val in suffreq.items():\n",
    "        normSuffFreq[key] = val/sumSuf\n",
    "        norm2SuffFreq[key] = val/len(tokens)\n",
    "    \n",
    "    sent = {\n",
    "        'fullSent' : sentimentGrams([tokens]),\n",
    "        'halfSent1' : sentimentGrams([tokens[:int(len(tokens)/2)]]),\n",
    "        'halfSent2' : sentimentGrams([tokens[int(len(tokens)/2):]]),\n",
    "        'thirdSent1' : sentimentGrams([tokens[:int(len(tokens)/3)]]),\n",
    "        'thirdSent2' : sentimentGrams([tokens[int(len(tokens)/3):2*int(len(tokens)/3)]]),\n",
    "        'thirdSent3' : sentimentGrams([tokens[2*int(len(tokens)/3):]]),\n",
    "        'quartSent1' : sentimentGrams([tokens[:int(len(tokens)/4)]]),\n",
    "        'quartSent2' : sentimentGrams([tokens[int(len(tokens)/4):2*int(len(tokens)/4)]]),\n",
    "        'quartSent3' : sentimentGrams([tokens[2*int(len(tokens)/4):3*int(len(tokens)/4)]]),\n",
    "        'quartSent4' : sentimentGrams([tokens[3*int(len(tokens)/4):]])\n",
    "    }\n",
    "    sentCompound = {}\n",
    "    for key, val in sent.items():\n",
    "        sentCompound[key+\"Vader\"] = val[0]['Vader']['compound'] + 1\n",
    "        sentCompound[key+\"LiuHu\"] = val[0]['LiuHu']['compound'] + 1\n",
    "    \n",
    "    capFreq = capLetterFreq(ull)\n",
    "    allCapsFreq = cases.count('AC')/len(cases)\n",
    "    normSuffFreq = keyToStr(normSuffFreq)\n",
    "    norm2SuffFreq = keyToStr(norm2SuffFreq)\n",
    "    toksuff = keyToStr(dict(freq(tokenSuffixes(tokens))))\n",
    "    unigrams = keyToStr(dict(freq(grams(tokens, 1))))\n",
    "    bigrams = keyToStr(dict(freq(grams(tokens, 2))))\n",
    "    trigrams = keyToStr(dict(freq(grams(tokens, 3))))\n",
    "    unigramsPos = keyToStr(dict(freq(grams(postags, 1))))\n",
    "    bigramsPos = keyToStr(dict(freq(grams(postags, 2))))\n",
    "    trigramsPos = keyToStr(dict(freq(grams(postags, 3))))\n",
    "    feat = {}\n",
    "    feat.update(unigrams)\n",
    "    feat.update(bigrams)\n",
    "    feat.update(trigrams)\n",
    "    feat.update(unigramsPos)\n",
    "    feat.update(bigramsPos)\n",
    "    feat.update(trigramsPos)\n",
    "    feat.update(puncuationFreqDict)\n",
    "    feat.update(toksuff)\n",
    "    feat.update(normSuffFreq)\n",
    "    feat.update(norm2SuffFreq)\n",
    "    feat.update(sentCompound)\n",
    "    feat.update({\"capFreq\":capFreq, \"allCapsFreq\":allCapsFreq})\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run features on tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213.051007\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "sarcasticTweets = tweet_iterate(\"../json/sarcastic/unique.json\", key=\"text\")\n",
    "sarcasticFeats = [(feature(repr(tweet)), True) for tweet in sarcasticTweets]\n",
    "print((datetime.datetime.now()-start).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232.341769\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "seriousTweets = list(tweet_iterate(\"../json/non_sarcastic/unique.json\", key=\"text\"))\n",
    "shuffle(seriousTweets)\n",
    "seriousFeats = [(feature(repr(tweet)), False) for tweet in seriousTweets[:len(sarcasticFeats)]]\n",
    "print((datetime.datetime.now()-start).total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featTup = sarcasticFeats + seriousFeats\n",
    "shuffle(featTup)\n",
    "pickle.dump(featTup, open('pickledfeatures/feats.pickle', 'wb'))\n",
    "(features, sarcasm) = list(zip(*featTup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pk = pickle.load(open('pickledfeatures/feats.pickle', 'rb'))\n",
    "(features, sarcasm) = list(zip(*pk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vectorizer and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "(X,y) = (dv.fit_transform(features), np.array(sarcasm))\n",
    "pickle.dump((X,y,dv), open('pickledfeatures/allFeaturesAndVectorizer.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Vectorizer and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X,y,dv) = pickle.load(open('pickledfeatures/allFeaturesAndVectorizer.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly split vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=10, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting itteration 0: 2017-04-06 15:51:04.126401\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train...\n",
      "Trained:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 19\n",
      "Trained:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 77\n",
      "Trained:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\n",
      "Trained:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\n",
      "Trained:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\n",
      "\n",
      "\n",
      "Starting to test...\n",
      "Tested:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.804975\n",
      "Tested:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.808824\n",
      "Tested:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\tScore:\t0.782848\n",
      "Tested:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\tScore:\t0.761682\n",
      "Tested:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\tScore:\t0.751649\n",
      "VC1:0.801677\n",
      "VC2:0.804700\n",
      "Itteration time:\t298\n",
      "Total elapsed time:\t298\n",
      "\n",
      "\n",
      "Starting itteration 1: 2017-04-06 15:56:03.003317\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train...\n",
      "Trained:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 25\n",
      "Trained:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 76\n",
      "Trained:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\n",
      "Trained:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\n",
      "Trained:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\n",
      "\n",
      "\n",
      "Starting to test...\n",
      "Tested:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.802089\n",
      "Tested:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.802639\n",
      "Tested:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\tScore:\t0.778175\n",
      "Tested:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\tScore:\t0.758109\n",
      "Tested:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\tScore:\t0.745052\n",
      "VC1:0.797279\n",
      "VC2:0.804975\n",
      "Itteration time:\t316\n",
      "Total elapsed time:\t615\n",
      "\n",
      "\n",
      "Starting itteration 2: 2017-04-06 16:01:19.833919\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train...\n",
      "Trained:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 28\n",
      "Trained:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 76\n",
      "Trained:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\n",
      "Trained:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\n",
      "Trained:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\n",
      "\n",
      "\n",
      "Starting to test...\n",
      "Tested:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.807724\n",
      "Tested:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.803051\n",
      "Tested:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\tScore:\t0.766080\n",
      "Tested:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\tScore:\t0.757834\n",
      "Tested:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\tScore:\t0.750275\n",
      "VC1:0.802089\n",
      "VC2:0.806212\n",
      "Itteration time:\t326\n",
      "Total elapsed time:\t941\n",
      "\n",
      "\n",
      "Starting itteration 3: 2017-04-06 16:06:45.851126\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train...\n",
      "Trained:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 32\n",
      "Trained:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 74\n",
      "Trained:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\n",
      "Trained:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\n",
      "Trained:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\n",
      "\n",
      "\n",
      "Starting to test...\n",
      "Tested:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.802914\n",
      "Tested:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.800577\n",
      "Tested:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\tScore:\t0.768004\n",
      "Tested:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\tScore:\t0.754810\n",
      "Tested:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\tScore:\t0.739830\n",
      "VC1:0.793843\n",
      "VC2:0.799753\n",
      "Itteration time:\t338\n",
      "Total elapsed time:\t1280\n",
      "\n",
      "\n",
      "Starting itteration 4: 2017-04-06 16:12:24.792015\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train...\n",
      "Trained:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 30\n",
      "Trained:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 75\n",
      "Trained:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\n",
      "Trained:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\n",
      "Trained:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\n",
      "\n",
      "\n",
      "Starting to test...\n",
      "Tested:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.808961\n",
      "Tested:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.806899\n",
      "Tested:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\tScore:\t0.710555\n",
      "Tested:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\tScore:\t0.764019\n",
      "Tested:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\tScore:\t0.750687\n",
      "VC1:0.805937\n",
      "VC2:0.809648\n",
      "Itteration time:\t333\n",
      "Total elapsed time:\t1614\n",
      "\n",
      "\n",
      "Starting itteration 5: 2017-04-06 16:17:58.720708\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train...\n",
      "Trained:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 34\n",
      "Trained:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 79\n",
      "Trained:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\n",
      "Trained:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\n",
      "Trained:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\n",
      "\n",
      "\n",
      "Starting to test...\n",
      "Tested:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.808824\n",
      "Tested:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.804013\n",
      "Tested:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\tScore:\t0.779687\n",
      "Tested:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\tScore:\t0.756872\n",
      "Tested:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\tScore:\t0.742991\n",
      "VC1:0.802089\n",
      "VC2:0.799753\n",
      "Itteration time:\t350\n",
      "Total elapsed time:\t1965\n",
      "\n",
      "\n",
      "Starting itteration 6: 2017-04-06 16:23:49.288832\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train...\n",
      "Trained:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 27\n",
      "Trained:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 76\n",
      "Trained:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\n",
      "Trained:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\n",
      "Trained:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\n",
      "\n",
      "\n",
      "Starting to test...\n",
      "Tested:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.812122\n",
      "Tested:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.813222\n",
      "Tested:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\tScore:\t0.794667\n",
      "Tested:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\tScore:\t0.764431\n",
      "Tested:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\tScore:\t0.746564\n",
      "VC1:0.805525\n",
      "VC2:0.810610\n",
      "Itteration time:\t329\n",
      "Total elapsed time:\t2294\n",
      "\n",
      "\n",
      "Starting itteration 7: 2017-04-06 16:29:18.962109\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train...\n",
      "Trained:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 27\n",
      "Trained:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 75\n",
      "Trained:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\n",
      "Trained:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\n",
      "Trained:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\n",
      "\n",
      "\n",
      "Starting to test...\n",
      "Tested:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.808686\n",
      "Tested:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.804288\n",
      "Tested:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\tScore:\t0.785459\n",
      "Tested:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\tScore:\t0.761682\n",
      "Tested:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\tScore:\t0.747664\n",
      "VC1:0.799065\n",
      "VC2:0.804288\n",
      "Itteration time:\t327\n",
      "Total elapsed time:\t2622\n",
      "\n",
      "\n",
      "Starting itteration 8: 2017-04-06 16:34:46.893696\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train...\n",
      "Trained:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 28\n",
      "Trained:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 77\n",
      "Trained:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\n",
      "Trained:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\n",
      "Trained:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\n",
      "\n",
      "\n",
      "Starting to test...\n",
      "Tested:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.808136\n",
      "Tested:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.805800\n",
      "Tested:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\tScore:\t0.777900\n",
      "Tested:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\tScore:\t0.768966\n",
      "Tested:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\tScore:\t0.753299\n",
      "VC1:0.806487\n",
      "VC2:0.808549\n",
      "Itteration time:\t320\n",
      "Total elapsed time:\t2942\n",
      "\n",
      "\n",
      "Starting itteration 9: 2017-04-06 16:40:07.031321\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train...\n",
      "Trained:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 32\n",
      "Trained:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 76\n",
      "Trained:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\n",
      "Trained:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\n",
      "Trained:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\n",
      "\n",
      "\n",
      "Starting to test...\n",
      "Tested:\t0\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.804838\n",
      "Tested:\t1\t<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.801127\n",
      "Tested:\t2\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 0\tScore:\t0.778450\n",
      "Tested:\t3\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 0\tScore:\t0.764431\n",
      "Tested:\t4\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 0\tScore:\t0.753848\n",
      "VC1:0.799753\n",
      "VC2:0.803326\n",
      "Itteration time:\t330\n",
      "Total elapsed time:\t3273\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "results = {}\n",
    "startTime=datetime.datetime.now()\n",
    "for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "    startItterationTime=datetime.datetime.now()\n",
    "    print(\"\\n\\nStarting itteration %d: \"%(i)+ str(startItterationTime))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(\"Features before reduction: \" + str(X_train.shape))\n",
    "    reducer = SelectPercentile(score_func=f_classif, percentile=1)\n",
    "    X_train = reducer.fit_transform(X_train,y_train)\n",
    "    X_test = reducer.transform(X_test)\n",
    "    print(\"Features after reduction: \" + str(str(X_train.shape)))\n",
    "    classifiers = [\n",
    "        LogisticRegression(n_jobs=-1),\n",
    "        #LogisticRegression(solver='sag', max_iter=1000, n_jobs=-1, warm_start=True),\n",
    "        #SGDClassifier(loss='log', penalty='elasticnet', n_jobs=-1),\n",
    "        #BernoulliNB(alpha=0.2, binarize=0.4),\n",
    "        #MultinomialNB(alpha=0),\n",
    "    ]\n",
    "    print(\"\\n\\nStarting to train...\")\n",
    "    for n, c in enumerate(classifiers):\n",
    "            s = datetime.datetime.now()\n",
    "            c.fit(X_train, y_train)\n",
    "            time = (datetime.datetime.now()-s).total_seconds()\n",
    "            results[(i,n,str(type(c)))] = {'trainTime':time}\n",
    "            print(\"Trained:\\t%d\\t%s\\tTime: %d\" % (n,str(type(c)), time))\n",
    "    print(\"\\n\\nStarting to test...\")\n",
    "    for n, c in enumerate(classifiers):\n",
    "            s = datetime.datetime.now()\n",
    "            score = c.score(X_test, y_test)\n",
    "            time = (datetime.datetime.now()-s).total_seconds()\n",
    "            results[(i,n,str(type(c)))]['testTime'] = time\n",
    "            results[(i,n,str(type(c)))]['score'] = score\n",
    "            print(\"Tested:\\t%d\\t%s\\tTime: %d\\tScore:\\t%f\" % (n,str(type(c)), time, score))\n",
    "    pickle.dump((classifiers,dv),open('pickled/'+re.sub(r'[ :<>\".*,|\\/]+', \"\", str(startTime))+\" \"+str(i)+'.pickle', 'wb'))\n",
    "    \n",
    "    vc1 = VotingClassifier(estimators=[(' '.join([str(n),str(type(c))]),c) for n, c in enumerate(classifiers)],\n",
    "                          voting='soft',\n",
    "                          weights=[3,2,1,1,1])\n",
    "    vc2 = VotingClassifier(estimators=[(' '.join([str(n),str(type(c))]),c) for n, c in enumerate(classifiers)],\n",
    "                         voting='hard')\n",
    "    vc1.fit(X_train, y_train)\n",
    "    vc2.fit(X_train, y_train)\n",
    "    print('VC1:%f'%vc1.score(X_test, y_test))\n",
    "    print('VC2:%f'%vc2.score(X_test, y_test))\n",
    "    \n",
    "    stopItterationTime=datetime.datetime.now()\n",
    "    print(\"Itteration time:\\t%d\" % (stopItterationTime-startItterationTime).total_seconds())\n",
    "    print(\"Total elapsed time:\\t%d\" % (stopItterationTime-startTime).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting itteration 0: 2017-04-06 13:33:04.153329\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train & Test...\n",
      "\t0\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 31\tParams::\t{'penalty': 'none', 'loss': 'perceptron'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.80      0.71      0.75      3638\n",
      "       True       0.74      0.82      0.78      3638\n",
      "\n",
      "avg / total       0.77      0.76      0.76      7276\n",
      "\n",
      "\t1\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 210\tParams::\t{'binarize': 0.40000000000000002, 'alpha': 0.20000000000000001}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.77      0.77      3638\n",
      "       True       0.77      0.76      0.77      3638\n",
      "\n",
      "avg / total       0.77      0.77      0.77      7276\n",
      "\n",
      "\t2\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 90\tParams::\t{'alpha': 0.0}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.78      0.76      3638\n",
      "       True       0.77      0.74      0.75      3638\n",
      "\n",
      "avg / total       0.76      0.76      0.76      7276\n",
      "\n",
      "Itteration time:\t338\n",
      "Total elapsed time:\t338\n",
      "\n",
      "\n",
      "Starting itteration 1: 2017-04-06 13:38:42.645291\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train & Test...\n",
      "\t0\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 31\tParams::\t{'penalty': 'elasticnet', 'loss': 'log'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.73      0.77      3638\n",
      "       True       0.76      0.83      0.79      3638\n",
      "\n",
      "avg / total       0.79      0.78      0.78      7276\n",
      "\n",
      "\t1\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 213\tParams::\t{'binarize': 0.59999999999999998, 'alpha': 0.10000000000000001}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.77      0.76      3638\n",
      "       True       0.77      0.75      0.76      3638\n",
      "\n",
      "avg / total       0.76      0.76      0.76      7276\n",
      "\n",
      "\t2\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 91\tParams::\t{'alpha': 0.0}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.77      0.75      3638\n",
      "       True       0.76      0.72      0.74      3638\n",
      "\n",
      "avg / total       0.75      0.75      0.75      7276\n",
      "\n",
      "Itteration time:\t342\n",
      "Total elapsed time:\t681\n",
      "\n",
      "\n",
      "Starting itteration 2: 2017-04-06 13:44:25.416767\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train & Test...\n",
      "\t0\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 30\tParams::\t{'penalty': 'none', 'loss': 'perceptron'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.71      0.75      3638\n",
      "       True       0.74      0.80      0.77      3638\n",
      "\n",
      "avg / total       0.76      0.76      0.76      7276\n",
      "\n",
      "\t1\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 212\tParams::\t{'binarize': 0.20000000000000001, 'alpha': 0.20000000000000001}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.76      0.76      3638\n",
      "       True       0.76      0.76      0.76      3638\n",
      "\n",
      "avg / total       0.76      0.76      0.76      7276\n",
      "\n",
      "\t2\t<class 'sklearn.naive_bayes.MultinomialNB'>\tTime: 90\tParams::\t{'alpha': 0.0}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.77      0.76      3638\n",
      "       True       0.76      0.74      0.75      3638\n",
      "\n",
      "avg / total       0.75      0.75      0.75      7276\n",
      "\n",
      "Itteration time:\t340\n",
      "Total elapsed time:\t1021\n",
      "\n",
      "\n",
      "Starting itteration 3: 2017-04-06 13:50:06.129504\n",
      "Features before reduction: (58206, 1307531)\n",
      "Features after reduction: (58206, 13075)\n",
      "\n",
      "\n",
      "Starting to train & Test...\n",
      "\t0\t<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\tTime: 30\tParams::\t{'penalty': 'elasticnet', 'loss': 'log'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.68      0.93      0.79      3638\n",
      "       True       0.89      0.56      0.69      3638\n",
      "\n",
      "avg / total       0.79      0.75      0.74      7276\n",
      "\n",
      "\t1\t<class 'sklearn.naive_bayes.BernoulliNB'>\tTime: 211\tParams::\t{'binarize': 0.5, 'alpha': 0.30000000000000004}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.78      0.78      3638\n",
      "       True       0.78      0.77      0.78      3638\n",
      "\n",
      "avg / total       0.78      0.78      0.78      7276\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-093d79cd652a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m_safe_split\u001b[0;34m(estimator, X, y, indices, train_indices)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mX_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mX_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[0;34m(X, indices)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# [[1,2],j] or [[1,2],1:2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mextracted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mP\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mextracted\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    504\u001b[0m            \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m            \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m            indptr, indices, data)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "results = {}\n",
    "startTime=datetime.datetime.now()\n",
    "for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "    startItterationTime=datetime.datetime.now()\n",
    "    print(\"\\n\\nStarting itteration %d: \"%(i)+ str(startItterationTime))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(\"Features before reduction: \" + str(X_train.shape))\n",
    "    reducer = SelectPercentile(score_func=f_classif, percentile=1)\n",
    "    X_train = reducer.fit_transform(X_train,y_train)\n",
    "    X_test = reducer.transform(X_test)\n",
    "    print(\"Features after reduction: \" + str(str(X_train.shape)))\n",
    "    classifiers = [\n",
    "        #(SGDClassifier(penalty='elasticnet', n_jobs=-1), {'loss':['log','modified_huber','perceptron'], 'penalty':['none','l1','elasticnet','l2']}), \n",
    "        #(BernoulliNB(),{'alpha':list(np.arange(0,20,0.1)), 'binarize':list(np.arange(0.1,0.9,0.1))}),\n",
    "        #(MultinomialNB(),{'alpha':list(np.arange(0,20,0.1))})\n",
    "    ]    \n",
    "    print(\"\\n\\nStarting to train & Test...\")\n",
    "    for n, (c,options) in enumerate(classifiers):\n",
    "            try:\n",
    "                clf= RandomizedSearchCV(c,options, cv=10, n_iter=100)\n",
    "                s = datetime.datetime.now()\n",
    "                clf.fit(X_train, y_train)\n",
    "            except ValueError:\n",
    "                clf= GridSearchCV(c,options, cv=10)\n",
    "                s = datetime.datetime.now()\n",
    "                clf.fit(X_train, y_train)\n",
    "            time = (datetime.datetime.now()-s).total_seconds()\n",
    "            y_true, y_pred = y_test, clf.predict(X_test)\n",
    "            print(\"\\t%d\\t%s\\tTime: %d\\tParams::\\t%s\" % (n,str(type(c)), time, str(clf.best_params_)))\n",
    "            print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    stopItterationTime=datetime.datetime.now()\n",
    "    print(\"Itteration time:\\t%d\" % (stopItterationTime-startItterationTime).total_seconds())\n",
    "    print(\"Total elapsed time:\\t%d\" % (stopItterationTime-startTime).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
