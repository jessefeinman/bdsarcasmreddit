{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import re\n",
    "from os import listdir, SEEK_END\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nlp\n",
    "import ml\n",
    "import numpy as np\n",
    "from dvs import DictVectorizerPartial\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "list_re = [\n",
    "    r\"(\\/sarcasm)\",\n",
    "    r\"(&lt;\\/?sarcasm&gt)\",\n",
    "    r\"(#sarcasm)\",\n",
    "    r\"(\\s*\\/s\\s*$)\"\n",
    "          ]\n",
    "sarcasm_re = re.compile('|'.join(list_re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df_rdd = sqlContext.read.format('json').load('test.json')\n",
    "rdd = df_rdd.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filterComments(generator):\n",
    "    import nlp\n",
    "    import ml\n",
    "    pop = []\n",
    "    for comment in generator:\n",
    "        try:\n",
    "            text = comment['body'].lower()\n",
    "            if 10 <= len(text) <= 120:\n",
    "                if sarcasm_re.search(text) is not None:\n",
    "                    yield (True, ml.flattenDict(nlp.feature(comment['body'], nlp.cleanTokensReddit)))\n",
    "                else:\n",
    "                    pop.append(comment['body'])\n",
    "                    if len(pop) == 1:#set to 1300\n",
    "                        yield (False, ml.flattenDict(nlp.feature(random.choice(pop), nlp.cleanTokensReddit)))\n",
    "                        pop = []\n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "features = rdd.mapPartitions(filterComments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getVocab(gen):\n",
    "    for sarc, features in gen:\n",
    "        for key in features:\n",
    "            yield key\n",
    "\n",
    "vocab = dict(features.mapPartitions(getVocab).distinct().zipWithIndex().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvp = DictVectorizerPartial(vocab=vocab)\n",
    "def vectorize(gen, dv):\n",
    "    blocksize = 100000\n",
    "    sarclst = []\n",
    "    featlst = []\n",
    "    for sarc, features in gen:\n",
    "        sarclst.append(sarc)\n",
    "        featlst.append(features)\n",
    "        if len(sarclst) == blocksize:\n",
    "            yield (sarclst, dv.transform(featlst))\n",
    "            sarclst = []\n",
    "            featlst = []\n",
    "    yield (sarclst, dv.transform(featlst))\n",
    "vdvp = lambda gen: vectorize(gen, dvp)\n",
    "\n",
    "csrs = features.mapPartitions(vdvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(sarclst, matricies) = zip(*csrs.collect())\n",
    "sarclst = list(sarclst)\n",
    "matricies = list(matricies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.array(reduce(lambda a,b: a+b, sarclst))\n",
    "X = scipy.sparse.vstack(matricies, format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered tt\n",
      "entered sss\n",
      "split data\n",
      "Starting to train <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.997340\n",
      "entered sss\n",
      "split data\n",
      "Starting to train <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.997340\n",
      "entered sss\n",
      "split data\n",
      "Starting to train <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.997340\n",
      "entered sss\n",
      "split data\n",
      "Starting to train <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\tTime: 0\tScore:\t0.997340\n"
     ]
    }
   ],
   "source": [
    "results = ml.trainTest(X,\n",
    "                       y,\n",
    "                       classifiers=[LogisticRegression(n_jobs=-1)],\n",
    "                       reduce=0,\n",
    "                       splits=4,\n",
    "                       trainsize=0.8,\n",
    "                       testsize=0.2)\n",
    "pickle.dump(results, open('trained-logistic-classifier.pickle', 'wb'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
